{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning with Vox Politics\n",
    "\n",
    "For this capstone I have found a data set that contains many articles from Vox. You can see the data set for yourself here:\n",
    "\n",
    "[Vox Articles on data.world](https://data.world/elenadata/vox-articles)\n",
    "\n",
    "Using the main body text of these articles, I would like to create a model that successfully predicts the authors. For this to be more challenging, I will also only use articles that have been categorized as \"Politics & Policy\" so that the contents are generally similar. So let's begin by importing all the necessary modules and taking a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Modules for making the model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data cleaning and feature importance\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# K-Means module\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Spectral Clustering module\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Mean Shift modules\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Metrics to evaluate models\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_on</th>\n",
       "      <th>slug</th>\n",
       "      <th>blurb</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitcoin is down 60 percent this year. Here's w...</td>\n",
       "      <td>Timothy B. Lee</td>\n",
       "      <td>Business &amp; Finance</td>\n",
       "      <td>2014-03-31 14:01:30</td>\n",
       "      <td>2014-12-16 16:37:36</td>\n",
       "      <td>http://www.vox.com/2014/3/31/5557170/bitcoin-b...</td>\n",
       "      <td>Bitcoins have lost more than 60 percent of the...</td>\n",
       "      <td>&lt;p&gt;The markets haven't been kind to&lt;span&gt; &lt;/sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 health problems marijuana could treat better...</td>\n",
       "      <td>German Lopez</td>\n",
       "      <td>War on Drugs</td>\n",
       "      <td>2014-03-31 15:44:21</td>\n",
       "      <td>2014-11-17 00:20:33</td>\n",
       "      <td>http://www.vox.com/2014/3/31/5557700/six-probl...</td>\n",
       "      <td>Medical marijuana could fill gaps that current...</td>\n",
       "      <td>&lt;p&gt;Twenty states have so far legalized the med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 charts that explain the history of global we...</td>\n",
       "      <td>Matthew Yglesias</td>\n",
       "      <td>Business &amp; Finance</td>\n",
       "      <td>2014-04-10 13:30:01</td>\n",
       "      <td>2014-12-16 15:47:02</td>\n",
       "      <td>http://www.vox.com/2014/4/10/5561608/9-charts-...</td>\n",
       "      <td>These nine charts from Thomas Piketty's new bo...</td>\n",
       "      <td>&lt;p&gt;Thomas Piketty's book &lt;i&gt;Capital in the 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remember when legal marijuana was going to sen...</td>\n",
       "      <td>German Lopez</td>\n",
       "      <td>Criminal Justice</td>\n",
       "      <td>2014-04-03 23:25:55</td>\n",
       "      <td>2014-05-06 21:58:42</td>\n",
       "      <td>http://www.vox.com/2014/4/3/5563134/marijuana-...</td>\n",
       "      <td>Three months after legalizing marijuana, Denve...</td>\n",
       "      <td>&lt;p&gt;&lt;span&gt;When Colorado legalized recreational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obamacare succeeded for one simple reason: it'...</td>\n",
       "      <td>Sarah Kliff</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>2014-04-01 20:26:14</td>\n",
       "      <td>2014-11-18 15:09:14</td>\n",
       "      <td>http://www.vox.com/2014/4/1/5570780/the-two-re...</td>\n",
       "      <td>After a catastrophic launch, Obamacare still s...</td>\n",
       "      <td>&lt;p&gt;There's a very simple reason that Obamacare...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title            author  \\\n",
       "0  Bitcoin is down 60 percent this year. Here's w...    Timothy B. Lee   \n",
       "1  6 health problems marijuana could treat better...      German Lopez   \n",
       "2  9 charts that explain the history of global we...  Matthew Yglesias   \n",
       "3  Remember when legal marijuana was going to sen...      German Lopez   \n",
       "4  Obamacare succeeded for one simple reason: it'...       Sarah Kliff   \n",
       "\n",
       "             category       published_date           updated_on  \\\n",
       "0  Business & Finance  2014-03-31 14:01:30  2014-12-16 16:37:36   \n",
       "1        War on Drugs  2014-03-31 15:44:21  2014-11-17 00:20:33   \n",
       "2  Business & Finance  2014-04-10 13:30:01  2014-12-16 15:47:02   \n",
       "3    Criminal Justice  2014-04-03 23:25:55  2014-05-06 21:58:42   \n",
       "4         Health Care  2014-04-01 20:26:14  2014-11-18 15:09:14   \n",
       "\n",
       "                                                slug  \\\n",
       "0  http://www.vox.com/2014/3/31/5557170/bitcoin-b...   \n",
       "1  http://www.vox.com/2014/3/31/5557700/six-probl...   \n",
       "2  http://www.vox.com/2014/4/10/5561608/9-charts-...   \n",
       "3  http://www.vox.com/2014/4/3/5563134/marijuana-...   \n",
       "4  http://www.vox.com/2014/4/1/5570780/the-two-re...   \n",
       "\n",
       "                                               blurb  \\\n",
       "0  Bitcoins have lost more than 60 percent of the...   \n",
       "1  Medical marijuana could fill gaps that current...   \n",
       "2  These nine charts from Thomas Piketty's new bo...   \n",
       "3  Three months after legalizing marijuana, Denve...   \n",
       "4  After a catastrophic launch, Obamacare still s...   \n",
       "\n",
       "                                                body  \n",
       "0  <p>The markets haven't been kind to<span> </sp...  \n",
       "1  <p>Twenty states have so far legalized the med...  \n",
       "2  <p>Thomas Piketty's book <i>Capital in the 21s...  \n",
       "3  <p><span>When Colorado legalized recreational ...  \n",
       "4  <p>There's a very simple reason that Obamacare...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the full TSV file\n",
    "raw_df = pd.read_csv('dsjVoxArticles.tsv', sep='\\t', header=0)\n",
    "\n",
    "# Take a look at it\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded, let's find and take out the top 10 authors in the Politics & Policy category to build our models off of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 P&P authors and how many articles they've written:\n",
      "Matthew Yglesias    198\n",
      "Andrew Prokop       174\n",
      "German Lopez        168\n",
      "Sarah Kliff         142\n",
      "Dara Lind           103\n",
      "Dylan Matthews      100\n",
      "Libby Nelson         96\n",
      "Timothy B. Lee       73\n",
      "Ezra Klein           70\n",
      "Jonathan Allen       61\n",
      "Name: author, dtype: int64\n",
      "\n",
      " Total number of articles by the top 10: 1185\n"
     ]
    }
   ],
   "source": [
    "# Take just the politics and policy articles\n",
    "main_df = raw_df[raw_df['category'] == 'Politics & Policy']\n",
    "\n",
    "# Print out the top ten authors from that list and our total # of articles\n",
    "top10 = main_df.author.value_counts()[:10]\n",
    "print(\"Top 10 P&P authors and how many articles they've written:\")\n",
    "print(top10)\n",
    "print('\\n', \"Total number of articles by the top 10:\", top10.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a dataframe with just these authors, and the main body of their articles. We'll also have to clean the text of all the html code that was picked up when the creator of this data set scraped it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Matthew Yglesias</td>\n",
       "      <td>Patricia Arquette's speech about the gender pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Andrew Prokop</td>\n",
       "      <td>Who really matters in our democracy — the gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Andrew Prokop</td>\n",
       "      <td>We've written about gerrymandering here on Vox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Ezra Klein</td>\n",
       "      <td>Presidents consistently overpromise and underd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Dylan Matthews</td>\n",
       "      <td>Let's imagine Daniel and Henry are vacationing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                               body\n",
       "21   Matthew Yglesias  Patricia Arquette's speech about the gender pa...\n",
       "53      Andrew Prokop  Who really matters in our democracy — the gene...\n",
       "141     Andrew Prokop  We've written about gerrymandering here on Vox...\n",
       "193        Ezra Klein  Presidents consistently overpromise and underd...\n",
       "209    Dylan Matthews  Let's imagine Daniel and Henry are vacationing..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list from the names of the top 10 and take their works for a new dataframe\n",
    "t10_list = top10.keys()\n",
    "\n",
    "top10_df = main_df[main_df['author'].isin(t10_list)].copy()\n",
    "\n",
    "# Take all of the html coding out of the \"body\" column using beautiful soup\n",
    "top10_df['body'] = [BeautifulSoup(body).get_text() for body in top10_df['body']]\n",
    "\n",
    "# Drop the columns I won't need\n",
    "top10_df = top10_df[['author', 'body']]\n",
    "\n",
    "# Take a look at it\n",
    "top10_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our first two models require uniform sizes of clusters, we will just take the first 61 articles from each of these authors. This still leaves us with 610 total articles, so that should serve our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_unif_df = pd.DataFrame()\n",
    "\n",
    "for author in t10_list:\n",
    "    top10_unif_df = top10_unif_df.append(top10_df[top10_df['author'] == author].iloc[0:61,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! Now let's make sure we aren't missing any fields before we dive into the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 610 entries, 21 to 10650\n",
      "Data columns (total 2 columns):\n",
      "author    610 non-null object\n",
      "body      610 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Make sure we aren't missing any fields\n",
    "top10_unif_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're certain our data is ready to use, we can create our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create our feature variable\n",
    "X = top10_unif_df.body\n",
    "\n",
    "# Create our target categories\n",
    "Y = top10_unif_df.author\n",
    "\n",
    "# Split our data up into 25/75 for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Model\n",
    "\n",
    "The data is ready to be modeled, so we'll begin with a K-Means model. Since we know there are 10 authors, this is a logical model to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer so that we can see how long it takes\n",
    "km_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that will take us through the modeling process\n",
    "kmeans_pipe = Pipeline([\n",
    "    # Use TfidfVectorizer to select words and get rid of useless stop words\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', sublinear_tf=True)),\n",
    "    \n",
    "    # Select the best features to train from using the chi squared algorithm\n",
    "    ('chi', SelectKBest(chi2)),\n",
    "    \n",
    "    # Choose our classifier algorithm\n",
    "    ('clf', KMeans(n_clusters=10))\n",
    "])\n",
    "\n",
    "# Fit the data\n",
    "kmeans_model = kmeans_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index score: 0.04730302833673588\n",
      "The K-Means model took 1.8170316219329834 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "kmeans_pred = kmeans_model.fit_predict(X_test, y_test)\n",
    "\n",
    "# See how well it did\n",
    "print(\"Adjusted Rand Index score:\", metrics.adjusted_rand_score(y_test, kmeans_pred))\n",
    "print(\"The K-Means model took\", time.time() - km_start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Adjusted Rand Index score is so close to zero, it looks like this model is close to predicting at random. That's no good! Let's try something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering Model\n",
    "\n",
    "As we can again provide the number of clusters to spectral clustering, let's see how this algorithm performs instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer so that we can see how long it takes\n",
    "sc_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that will take us through the modeling process\n",
    "sc_pipe = Pipeline([\n",
    "    # Use TfidfVectorizer to select words and get rid of useless stop words\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', sublinear_tf=True)),\n",
    "    \n",
    "    # Select the best features to train from using the chi squared algorithm\n",
    "    ('chi', SelectKBest(chi2)),\n",
    "    \n",
    "    # Choose our classifier algorithm\n",
    "    ('clf', SpectralClustering(n_clusters=10))\n",
    "])\n",
    "\n",
    "# Fit the data\n",
    "sc_model = sc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index score: 0.05347068950096642\n",
      "The Spectral Clustering model took 1.7456982135772705 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "sc_pred = sc_model.fit_predict(X_test, y_test)\n",
    "\n",
    "# See how well it did\n",
    "print(\"Adjusted Rand Index score:\", metrics.adjusted_rand_score(y_test, sc_pred))\n",
    "print(\"The Spectral Clustering model took\", time.time() - sc_start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's a little better, but not by much. Let's try another approach then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Shift Model\n",
    "\n",
    "This should work better for our data since the clusters aren't necessarily the same size. Since we don't need uniform sizes for the clusters, we can go back to the full data with > 1000 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our feature variable\n",
    "X = top10_df.body\n",
    "\n",
    "# Create our target categories\n",
    "Y = top10_df.author\n",
    "\n",
    "# Split our data up into 25/75 for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer so that we can see how long it takes\n",
    "ms_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that will take us through the modeling process\n",
    "ms_pipe = Pipeline([\n",
    "    # Use TfidfVectorizer to select words and get rid of useless stop words\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', sublinear_tf=True)),\n",
    "    \n",
    "    # Select the best features to train from using the chi squared algorithm\n",
    "    ('chi', SelectKBest(chi2)),\n",
    "    \n",
    "    # Transform the sparse matrix into dense data so that MeanShift can use it\n",
    "    ('ftrans', FunctionTransformer(lambda x: x.todense(), validate=False)),\n",
    "    \n",
    "    # Choose our classifier algorithm\n",
    "    ('clf', MeanShift())\n",
    "])\n",
    "\n",
    "# Fit the data\n",
    "ms_model = ms_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index score: 0.04338273133219622\n",
      "The Spectral Clustering model took 16.928893566131592 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "ms_pred = ms_model.fit_predict(X_test, y_test)\n",
    "\n",
    "# See how well it did\n",
    "print(\"Adjusted Rand Index score:\", metrics.adjusted_rand_score(y_test, ms_pred))\n",
    "print(\"The Spectral Clustering model took\", time.time() - ms_start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
